# Awesome-Text/Image-to-3D

A list of Text/Img-to-3D works. This repo mainly contain the 3D learning from 2D priors model (stable diffusion, CLIP...) works. 


<details open>
<summary><strong>Text to 3D</strong></summary>
  
## <span style="font-size: smaller;">Before 2022</span>
- [Zero-Shot Text-Guided Object Generation with Dream Fields](https://arxiv.org/abs/2112.01455), Ajay Jain et al., CVPR 2022 | [github](https://github.com/google-research/google-research/tree/master/dreamfields)

- [CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation](https://arxiv.org/abs/2110.02624), Aditya Sanghi et al., CVPR 2022 | [github](https://github.com/AutodeskAILab/Clip-Forge)

- [CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields](https://arxiv.org/abs/2112.05139), Can Wang et al., CVPR 2022 |  [github](https://github.com/cassiePython/CLIPNeRF)

- [Clip-Mesh: Generating textured meshes from text using pretrained image-text models](https://dl.acm.org/doi/abs/10.1145/3550469.3555392), Mohammad Khalid, Nasir, et al., SIGGRAPH Asia 2022 | [github](https://github.com/NasirKhalid24/CLIP-Mesh)

- [Text2Mesh: Text-Driven Neural Stylization for Meshes](https://arxiv.org/abs/2112.03221), Oscar Michel, et al., CVPR 2022 | [github](https://github.com/threedle/text2mesh)

## 2022

- [DreamFusion: Text-to-3D using 2D Diffusion](https://arxiv.org/abs/2209.14988), Ben Poole, et al., ICLR 2022 | [project page](https://dreamfusion3d.github.io/) [github](https://github.com/threestudio-project/threestudio)

- [Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation](https://arxiv.org/abs/2212.00774), Haochen Wang, et al., CVPR 2023 | [project page]([https://dreamfusion3d.github.io/](https://pals.ttic.edu/p/score-jacobian-chaining)) [github](https://github.com/pals-ttic/sjc/)
 

- [Magic3D: High-Resolution Text-to-3D Content Creation](https://arxiv.org/abs/2211.10440), Chen-Hsuan Lin, et al ., CVPR 2023 | [project page](https://research.nvidia.com/labs/dir/magic3d/) [github](https://github.com/threestudio-project/threestudio)

- [Latent-NeRF for Shape-Guided Generation of 3D Shapes and Textures](https://arxiv.org/abs/2211.07600), Gal Metzer, et al., CVPR 2023 | [github](https://github.com/eladrich/latent-nerf)


## 2023
- [Shap·E: Generating Conditional 3D Implicit Functions](https://arxiv.org/abs/2305.02463), Heewoo Jun, et al., | [github](https://github.com/openai/shap-e)
  
- [ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation](https://arxiv.org/abs/2305.16213), Zhengyi Wang, et al., | [github](https://github.com/threestudio-project/threestudio)

- [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions](https://arxiv.org/abs/2303.12789), Ayaan Haque, et al., | [github](https://github.com/ayaanzhaque/instruct-nerf2nerf)

- [Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation](https://arxiv.org/abs/2303.13873), Rui Chen, et al., ICCV 2023 | [github](https://github.com/Gorilla-Lab-SCUT/Fantasia3D)

- [ATT3D: Amortized Text-to-3D Object Synthesis](https://arxiv.org/abs/2306.07349#:~:text=Text%2Dto%2D3D%20modelling%20has,optimization%20to%20create%203D%20objects.), Jonathan Lorraine., ICCV 2023 |  [project page](https://research.nvidia.com/labs/toronto-ai/ATT3D/)

- [DreamEditor: Text-Driven 3D Scene Editing with Neural Fields](https://arxiv.org/pdf/2306.13455.pdf), Jingyu Zhang, et al.,  Arxiv 2023

- [Vox-E Text-guided Voxel Editing of 3D Objects](https://arxiv.org/abs/2303.12048), Etai Sella, et al., ICCV 2023 | [github](https://github.com/TAU-VAILab/Vox-E)

- [SKED: Sketch-guided Text-based 3D Editing](https://arxiv.org/abs/2303.10735), Aryan Mikaeili, et al., ICCV 2023 | [project page](https://sked-paper.github.io/)

- [TextMesh: Generation of Realistic 3D Meshes From Text Prompts](https://arxiv.org/abs/2304.12439), Christina Tsalicoglou, et al., Arxiv 2023 | [github](https://github.com/threestudio-project/threestudio)

- [Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond.](https://arxiv.org/abs/2304.04968) Mohammadreza Armandpour, et al., Arxiv 2023 | [github](https://github.com/Perp-Neg/Perp-Neg-stablediffusion) 

</details>

<details open>
<summary><strong>Image to 3D</strong></summary>

## 2023
- [RealFusion 360◦ Reconstruction of Any Object from a Single Image](https://arxiv.org/abs/2302.10663), Luke Melas-Kyriazi, et al., ICCV 2023 | [github](https://github.com/lukemelas/realfusion)

- [Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors](https://arxiv.org/abs/2306.17843), Guocheng Qian, et al., | [github](https://github.com/guochengqian/Magic123)

- [One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization](https://arxiv.org/pdf/2306.16928.pdf), Minghua Liu, et al., | [github](https://github.com/One-2-3-45/One-2-3-45)

- [Nerdi: Single-view nerf synthesis with language-guided diffusion as general image priors](https://arxiv.org/pdf/2306.16928.pdf) Congyue Deng, et al., CVPR 2023

- [NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360° Views](https://arxiv.org/abs/2211.16431) Dejia Xu et al., CVPR 2023 | [github](https://github.com/VITA-Group/NeuralLift-360)

- [Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior](https://arxiv.org/abs/2303.14184) Junshu Tang et al., ICCV 2023 | [github](https://github.com/junshutang/Make-It-3D)

- [Zero-1-to-3: Zero-shot One Image to 3D Object](https://arxiv.org/abs/2303.11328) Ruoshi Liu, et al., ICCV2023 | [github](https://github.com/cvlab-columbia/zero123)
  </details>
